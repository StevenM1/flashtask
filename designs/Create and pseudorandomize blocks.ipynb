{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to generate blocks of trials\n",
    "Localizer, cognitive, and limbic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_localizer_block_single_effector(n_trials, response_modality='eye', \n",
    "                                           block_number=None, pseudorandomize=True, \n",
    "                                           add_timing=True, null_trials=0):\n",
    "    \n",
    "    # Only two trial types here: 'left' is correct, or 'right' is correct\n",
    "    trial_types = np.repeat([0, 1], repeats=n_trials/2)  # left/right is correct\n",
    "    \n",
    "    # Initialize arrays\n",
    "    cue_by_trial = np.zeros(n_trials, dtype='<U5')\n",
    "    correct_answers = np.zeros(n_trials, dtype=np.int8)\n",
    "\n",
    "    # Define the cues for every trial\n",
    "    cue_by_trial[(trial_types == 0) | (trial_types == 1)] = response_modality.upper()\n",
    "\n",
    "    # Define the responses ('correct answers')/directions for every trial\n",
    "    correct_answers[(trial_types == 0)] = 0  # 0 = respond LEFT\n",
    "    correct_answers[(trial_types == 1)] = 1  # 1 = respond RIGHT\n",
    "    \n",
    "    # Create dataframe for eas ier handling\n",
    "    trial_data = pd.DataFrame({'correct_answer': correct_answers,\n",
    "                               'cue': cue_by_trial,\n",
    "                               'trial_type': trial_types})\n",
    "    \n",
    "    # Should we pseudorandomize?\n",
    "    if pseudorandomize:\n",
    "        trial_data = Pseudorandomizer(trial_data, max_identical_iters={'correct_answer': 4}).run()\n",
    "    \n",
    "    trial_data['null_trial'] = False\n",
    "    if null_trials > 0:\n",
    "        trial_data = add_pseudorandom_null_trials(trial_data, n_null_trials=null_trials)\n",
    "    \n",
    "    # Add block number for completeness\n",
    "    if block_number is not None:\n",
    "        trial_data['block'] = block_number\n",
    "        trial_data['block_type'] = 'localizer'\n",
    "\n",
    "    # Usually, we also want to add the duration of all the 'trial phases'\n",
    "    if add_timing:\n",
    "        trial_data = get_block_timing(trial_data, phase_2=1, phase_3=0, phase_6=0)\n",
    "    \n",
    "    \n",
    "    trial_data['response_modality'] = trial_data['cue'].str.lower()\n",
    "    \n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cognitive_block(n_trials, block_number=None, response_modality=None, \n",
    "                           add_timing=True, pseudorandomize=True, n_null_trials=0):\n",
    "    \"\"\"\n",
    "    Creates a block of SAT-trials; mixing speed and accuracy trials\n",
    "    \"\"\"\n",
    "    trial_types = np.hstack((np.repeat([0, 1], repeats=n_trials / 4),   # SPEED cue, left/right corr\n",
    "                             np.repeat([2, 3], repeats=n_trials / 4)))  # ACCURACY cue, left/right corr\n",
    "\n",
    "    if trial_types.shape[0] != n_trials:\n",
    "        raise(ValueError('The provided n_trials (%d) could not be split into the correct number of trial types. '\n",
    "                         'Closest option is %d trials' % (n_trials, trial_types.shape[0])))\n",
    "\n",
    "    cue_by_trial = np.zeros(n_trials, dtype='<U5')\n",
    "    correct_answers = np.zeros(n_trials, dtype=np.int8)\n",
    "\n",
    "    cue_by_trial[(trial_types == 0) | (trial_types == 1)] = 'SPD'\n",
    "    cue_by_trial[(trial_types == 2) | (trial_types == 3)] = 'ACC'\n",
    "\n",
    "    correct_answers[(trial_types == 0) | (trial_types == 2)] = 0  # 0 = left is correct\n",
    "    correct_answers[(trial_types == 1) | (trial_types == 3)] = 1  # 1 = right is correct\n",
    "\n",
    "    # Create dataframe for easier handling\n",
    "    trial_data = pd.DataFrame({'correct_answer': correct_answers,\n",
    "                               'cue': cue_by_trial,\n",
    "                               'trial_type': trial_types})\n",
    "    \n",
    "    if pseudorandomize:\n",
    "        trial_data = Pseudorandomizer(trial_data, \n",
    "                                      max_identical_iters={'cue': 4, 'correct_answer': 4}).run()\n",
    "        \n",
    "    if n_null_trials > 0:\n",
    "        trial_data['null_trial'] = False\n",
    "        trial_data = add_pseudorandom_null_trials(trial_data, \n",
    "                                                  n_null_trials=n_null_trials, \n",
    "                                                  null_column_name='null_trial')\n",
    "\n",
    "    if block_number is not None:\n",
    "        trial_data['block'] = block_number\n",
    "        \n",
    "    if response_modality is not None:\n",
    "        trial_data['response_modality'] = response_modality\n",
    "        trial_data['block_type'] = 'cognitive_%s' % response_modality \n",
    "\n",
    "    if add_timing:\n",
    "        trial_data = get_block_timing(trial_data)  # Add default timing\n",
    "        \n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_limbic_block(n_trials, subject_number=1, block_number=None, \n",
    "                        response_modality=None, add_timing=True, pseudorandomize=True,\n",
    "                        n_null_trials=0):\n",
    "    \n",
    "    trial_types = np.hstack((np.repeat([0, 1], repeats=n_trials/6),    # Neutral cue, left/right corr\n",
    "                             np.repeat([2, 3], repeats=n_trials/6),    # Left cue, left/right corr\n",
    "                             np.repeat([4, 5], repeats=n_trials/6)))   # Right cue, left/right corr\n",
    "\n",
    "    if trial_types.shape[0] != n_trials:\n",
    "        raise(ValueError('The provided n_trials (%d) could not be split into the correct number of trial types. '\n",
    "                     'Closest option is %d trials' % (n_trials, trial_types.shape[0])))\n",
    "\n",
    "    cue_by_trial = np.zeros(n_trials, dtype='<U5')\n",
    "    correct_answers = np.zeros(n_trials, dtype=np.int8)\n",
    "\n",
    "    cue_by_trial[(trial_types == 0) | (trial_types == 1)] = 'NEU'\n",
    "    cue_by_trial[(trial_types == 2) | (trial_types == 3)] = 'LEFT'\n",
    "    cue_by_trial[(trial_types == 4) | (trial_types == 5)] = 'RIGHT'\n",
    "\n",
    "    correct_answers[(trial_types == 0) |\n",
    "                    (trial_types == 2) |\n",
    "                    (trial_types == 4)] = 0  # 0 = left is correct\n",
    "    correct_answers[(trial_types == 1) |\n",
    "                    (trial_types == 3) |\n",
    "                    (trial_types == 5)] = 1  # 1 = right is correct\n",
    "\n",
    "    # Create dataframe for easier handling\n",
    "    trial_data = pd.DataFrame({'correct_answer': correct_answers,\n",
    "                               'cue': cue_by_trial,\n",
    "                               'trial_type': trial_types})\n",
    "\n",
    "    if pseudorandomize:\n",
    "        trial_data = Pseudorandomizer(trial_data, \n",
    "                                      max_identical_iters={'cue': 4, 'correct_answer': 4}).run()\n",
    "    \n",
    "    if n_null_trials > 0:\n",
    "        trial_data['null_trial'] = False\n",
    "        trial_data = add_pseudorandom_null_trials(trial_data, \n",
    "                                                  n_null_trials=n_null_trials, \n",
    "                                                  null_column_name='null_trial')\n",
    "    \n",
    "    if block_number is not None:\n",
    "        trial_data['block'] = block_number\n",
    "        \n",
    "    if response_modality is not None:\n",
    "        trial_data['response_modality'] = response_modality\n",
    "        trial_data['block_type'] = 'limbic_%s' % response_modality \n",
    "\n",
    "    if add_timing:\n",
    "        trial_data = get_block_timing(trial_data)  # Add default timing\n",
    "\n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that creates timing columns for a block of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_timing(trial_data, phase_0=None, phase_1=None, phase_2=None, phase_3=None, phase_4=None, phase_5=None, phase_6=None, TR=2):\n",
    "    \"\"\"\n",
    "    Each trial consists of 7 phases.\n",
    "    \n",
    "    In phase_0, we wait for the scanner pulse. Note that phase_0 of trial n is the ITI after trial n-1. Set this timing always to 0: it is the `minimum` time to wait for the pulse\n",
    "    In phase_1, we show the pre-cue fixation cross. By default, timing is jittered (0s, 0.5s, 1s, 1.5s)\n",
    "    In phase_2, we show the cue. In decision-making trials, this is 4.8 seconds. For the localizer, it is 1 second.\n",
    "    In phase_3, we show the post-cue fixation cross. Timing is jittered (0s, 0.5s, 1s, 1.5s)\n",
    "    In phase_4, we show the stimulus. Default is 1.5s.\n",
    "    Phase 5 is defined as the period of stimulus presentation, after the participant made a response. The duration is determined by the participant RT, so not set here.\n",
    "    In phase_6, we show feedback. Default is 0.35s.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    trial_data['phase_0'] = 0 if phase_0 is None else phase_0\n",
    "    trial_data['phase_1'] = np.random.choice([0, .5, 1, 1.5], size=trial_data.shape[0]) if phase_1 is None else phase_1\n",
    "    trial_data['phase_2'] = 4.8 if phase_2 is None else phase_2\n",
    "    trial_data['phase_3'] = np.random.choice([0, .5, 1, 1.5], size=trial_data.shape[0]) if phase_3 is None else phase_3\n",
    "    trial_data['phase_4'] = 1.5 if phase_4 is None else phase_4\n",
    "    trial_data['phase_5'] = 0 if phase_5 is None else phase_5\n",
    "    trial_data['phase_6'] = 0.35 if phase_6 is None else phase_6\n",
    "\n",
    "    # Calculate duration of trial (depends on random, jittered durations of the fix cross)\n",
    "    trial_data['trial_duration'] = trial_data[['phase_' + str(x) for x in range(7)]].sum(axis=1)\n",
    "\n",
    "    # Because of TR = 2s, some trials can last 8 seconds, but most will last 10. Find trials with total time < 8 seconds\n",
    "    # We calculate the ITI as the difference between the minimum number of pulses necessary for all phases to show.\n",
    "    min_TRs = np.ceil(trial_data['trial_duration'].values / TR)\n",
    "    trial_data['phase_7'] = min_TRs*TR - trial_data['trial_duration'].values\n",
    "\n",
    "    # Recalculate trial duration so it includes the ITI\n",
    "    trial_data['trial_duration'] = trial_data[['phase_' + str(x) for x in range(8)]].sum(axis=1)\n",
    "\n",
    "    # Add trial start times relative to start of block\n",
    "    trial_data['trial_start_time_block'] = trial_data['trial_duration'].shift(1).cumsum()\n",
    "    trial_data.loc[0, 'trial_start_time_block'] = 0\n",
    "\n",
    "    # Add cue onset times relative to start of block\n",
    "    trial_data['cue_onset_time_block'] = trial_data['trial_start_time_block'] + \\\n",
    "                                         trial_data['phase_1']\n",
    "\n",
    "    # Add stimulus onset times relative to start of block\n",
    "    trial_data['stimulus_onset_time_block'] = trial_data['trial_start_time_block'] + \\\n",
    "                                              trial_data['phase_1'] + \\\n",
    "                                              trial_data['phase_2'] + \\\n",
    "                                              trial_data['phase_3']\n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for pseudorandomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pseudorandomizer(object):\n",
    "    \n",
    "    def __init__(self, data, max_identical_iters={'cue': 4, 'correct_answer': 4}):  \n",
    "        self.data = data\n",
    "        self.max_identical_iters = {x: y+1 for x, y in max_identical_iters.items()}\n",
    "                                    # add 1: if 4 rows is allowed, only give an error after 5 identical rows\n",
    "    \n",
    "    def check_trial_rows(self, data, row_n): \n",
    "        \"\"\"\n",
    "        Returns True if any of the conditions for pseudorandomization are violated for the given rows, \n",
    "        False if they are fine.\n",
    "        \"\"\"\n",
    "        \n",
    "        # First, check for the maximum iterations\n",
    "        for column, max_iter in self.max_identical_iters.items():\n",
    "            if row_n - max_iter < 0:\n",
    "                continue\n",
    "\n",
    "            # Select rows [max_iter-1 - row_n] we're going to check. Never select any row with index < 0\n",
    "            row_selection = [x for x in np.arange(row_n, row_n-max_iter, -1)]\n",
    "\n",
    "            # Next, we check if the selected rows only contain *1* trial type. \n",
    "            # If so, this means we have max_iter rows of the same trials, and we need to change something.\n",
    "            if data.iloc[row_selection][column].nunique() == 1:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def run(self, debug=False):\n",
    "        \"\"\"\n",
    "        Pseudorandomizes: makes sure that it is not possible to have more than x iterations for every type of column, specified in columns.\n",
    "        \"\"\"\n",
    "        # Start by copying from original data, and shuffle\n",
    "        self.data = self.data.sample(frac=1, \n",
    "                                     random_state=np.random.randint(0, 1e7, dtype='int')).reset_index(drop=True) \n",
    "        \n",
    "        if debug:\n",
    "            outer_while_i = 0\n",
    "            debug_print_after_i = 100\n",
    "\n",
    "        good_set = False\n",
    "        while not good_set:\n",
    "            if debug:\n",
    "                outer_while_i += 1\n",
    "\n",
    "            reshuffle = False  # Assume the dataset does not need reshuffling.\n",
    "            for row_n in range(0, self.data.shape[0]):\n",
    "\n",
    "                # Select rows [max_iter-1 - row_n] we're going to check\n",
    "\n",
    "                # Check if the current row, and the (max_iters-1) rows before, are the same value (number of unique values = 1).\n",
    "                # If so, then move the current row number to the bottom of the dataframe. However, we need to re-check the same four rows again\n",
    "                # after moving a row to the bottom: therefore, a while loop is necessary.\n",
    "                checked_row = False\n",
    "                n_attempts_at_moving = 0\n",
    "                \n",
    "                if debug:\n",
    "                    inner_while_i = 0\n",
    "                \n",
    "                while not checked_row:\n",
    "                    if debug:\n",
    "                        inner_while_i += 1\n",
    "                        if inner_while_i > debug_print_after_i:\n",
    "                            print('New inner loop started for current row')\n",
    "\n",
    "                    if self.check_trial_rows(self.data, row_n):\n",
    "                        if debug and inner_while_i > debug_print_after_i:\n",
    "                            print('Found too many consecutively identical rows.')\n",
    "\n",
    "                        # If there are too many consecutively identical rows at the bottom of the dataframe, \n",
    "                        # break and start over/shuffle\n",
    "                        if row_n >= (self.data.shape[0] - self.max_identical_iters[self.max_identical_iters.keys()[0]]):\n",
    "                            if debug and inner_while_i > debug_print_after_i:\n",
    "                                print('These occurred at row_n %d, which is at the bottom of the DF.' % row_n)\n",
    "\n",
    "                            checked_row = True\n",
    "                            reshuffle = True\n",
    "\n",
    "                        # Too many consecutive identical rows? Move row_n to the bottom, and check again with the new row_n.\n",
    "                        else:\n",
    "                            if debug and inner_while_i > debug_print_after_i:\n",
    "                                print('These occurred at row_n %d. Checking the remainder of the DF.' % row_n)\n",
    "\n",
    "                            # Check if moving to the bottom even makes sense: if all remaining values are identical, it doesn't.\n",
    "                            if (self.data.iloc[row_n:][self.max_identical_iters.keys()].nunique().values < 2).any():\n",
    "                                if debug and inner_while_i > debug_print_after_i:\n",
    "                                    print('All remaining values are identical. I should stop the for-loop, and start over.')\n",
    "\n",
    "                                checked_row = True\n",
    "                                reshuffle = True\n",
    "                            else:\n",
    "                                if n_attempts_at_moving < 50:\n",
    "                                    n_attempts_at_moving += 1\n",
    "\n",
    "                                    if debug and inner_while_i > debug_print_after_i:\n",
    "                                        print('Not all remaining values are identical. I should move the final part to the bottom.')\n",
    "\n",
    "                                    # If not, move the current row to the bottom\n",
    "                                    row_to_move = self.data.iloc[row_n,:]\n",
    "\n",
    "                                    # Delete row from df\n",
    "                                    self.data.drop(row_n, axis=0, inplace=True)\n",
    "\n",
    "                                    # Append original row to end. Make sure to reset index\n",
    "                                    self.data = self.data.append(row_to_move).reset_index(drop=True)\n",
    "\n",
    "                                # If we already tried moving the current row to the bottom for 50 times, let's forget about it and restart\n",
    "                                else:\n",
    "                                    checked_row = True\n",
    "                                    reshuffle = True\n",
    "                    else:\n",
    "                        if debug and inner_while_i > debug_print_after_i:\n",
    "                            print('Checked row, but the row is fine. Next row.')\n",
    "                        checked_row = True\n",
    "\n",
    "                if reshuffle:\n",
    "                    good_set = False\n",
    "                    break  # out of the for loop\n",
    "\n",
    "                # Reached the bottom of the dataframe, but no reshuffle call? Then we're set.\n",
    "                if row_n == self.data.shape[0]-1:\n",
    "                    good_set = True\n",
    "\n",
    "            if reshuffle:\n",
    "                # Shuffle, reset index to ensure trial_data.drop(row_n) rows\n",
    "                self.data = self.data.sample(frac=1, random_state=np.random.randint(0, 1e7, dtype='int')).reset_index(drop=True)\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "def add_pseudorandom_null_trials(data, min_row=4, max_row=4, min_n_rows_separate=7, \n",
    "                                n_null_trials=10, null_column_name=''):\n",
    "    \"\"\" \n",
    "    Adds null trials interspersed at pseudorandom locations. You can determine the minimum\n",
    "    number of trials at the start before a null trial, the minimum number of trials at the end in which no\n",
    "    nulls are shown, and the minimum number of trials that the null trials have to be separated \n",
    "    \"\"\"\n",
    "    \n",
    "    good_idx = False\n",
    "    while not good_idx:\n",
    "        indx = np.random.choice(np.arange(min_row, data.shape[0]-max_row), \n",
    "                                replace=False, size=n_null_trials)\n",
    "        diffs = np.diff(np.sort(indx))\n",
    "        if (diffs >= min_n_rows_separate).all():\n",
    "            good_idx = True\n",
    "    \n",
    "    data.index = np.setdiff1d(np.arange(data.shape[0] + n_null_trials), indx)\n",
    "    new_rows = pd.DataFrame({null_column_name: [True]*n_null_trials}, columns=data.columns, index=indx)\n",
    "    data = data.append(new_rows).sort_index()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order of blocks by participant\n",
    "\n",
    "- X = localizer hand\n",
    "- Y = localizer eye\n",
    "- A = cognitive, hand\n",
    "- B = cognitive, eye\n",
    "- C = limbic, hand\n",
    "- D = limbic, eye\n",
    "\n",
    "4 blocks, 4\\*3\\*2\\*1 = 4! = 24 block orders\n",
    "\n",
    "2 localizer 'blocks', 2\\*1 = 2 possible orders.\n",
    "In total, 48 possible block orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('X', 'Y', 'A', 'B', 'C', 'D'),\n",
      " ('X', 'Y', 'A', 'B', 'D', 'C'),\n",
      " ('X', 'Y', 'A', 'C', 'B', 'D'),\n",
      " ('X', 'Y', 'A', 'C', 'D', 'B'),\n",
      " ('X', 'Y', 'A', 'D', 'B', 'C'),\n",
      " ('X', 'Y', 'A', 'D', 'C', 'B'),\n",
      " ('X', 'Y', 'B', 'A', 'C', 'D'),\n",
      " ('X', 'Y', 'B', 'A', 'D', 'C'),\n",
      " ('X', 'Y', 'B', 'C', 'A', 'D'),\n",
      " ('X', 'Y', 'B', 'C', 'D', 'A'),\n",
      " ('X', 'Y', 'B', 'D', 'A', 'C'),\n",
      " ('X', 'Y', 'B', 'D', 'C', 'A'),\n",
      " ('X', 'Y', 'C', 'A', 'B', 'D'),\n",
      " ('X', 'Y', 'C', 'A', 'D', 'B'),\n",
      " ('X', 'Y', 'C', 'B', 'A', 'D'),\n",
      " ('X', 'Y', 'C', 'B', 'D', 'A'),\n",
      " ('X', 'Y', 'C', 'D', 'A', 'B'),\n",
      " ('X', 'Y', 'C', 'D', 'B', 'A'),\n",
      " ('X', 'Y', 'D', 'A', 'B', 'C'),\n",
      " ('X', 'Y', 'D', 'A', 'C', 'B'),\n",
      " ('X', 'Y', 'D', 'B', 'A', 'C'),\n",
      " ('X', 'Y', 'D', 'B', 'C', 'A'),\n",
      " ('X', 'Y', 'D', 'C', 'A', 'B'),\n",
      " ('X', 'Y', 'D', 'C', 'B', 'A'),\n",
      " ('Y', 'X', 'A', 'B', 'C', 'D'),\n",
      " ('Y', 'X', 'A', 'B', 'D', 'C'),\n",
      " ('Y', 'X', 'A', 'C', 'B', 'D'),\n",
      " ('Y', 'X', 'A', 'C', 'D', 'B'),\n",
      " ('Y', 'X', 'A', 'D', 'B', 'C'),\n",
      " ('Y', 'X', 'A', 'D', 'C', 'B'),\n",
      " ('Y', 'X', 'B', 'A', 'C', 'D'),\n",
      " ('Y', 'X', 'B', 'A', 'D', 'C'),\n",
      " ('Y', 'X', 'B', 'C', 'A', 'D'),\n",
      " ('Y', 'X', 'B', 'C', 'D', 'A'),\n",
      " ('Y', 'X', 'B', 'D', 'A', 'C'),\n",
      " ('Y', 'X', 'B', 'D', 'C', 'A'),\n",
      " ('Y', 'X', 'C', 'A', 'B', 'D'),\n",
      " ('Y', 'X', 'C', 'A', 'D', 'B'),\n",
      " ('Y', 'X', 'C', 'B', 'A', 'D'),\n",
      " ('Y', 'X', 'C', 'B', 'D', 'A'),\n",
      " ('Y', 'X', 'C', 'D', 'A', 'B'),\n",
      " ('Y', 'X', 'C', 'D', 'B', 'A'),\n",
      " ('Y', 'X', 'D', 'A', 'B', 'C'),\n",
      " ('Y', 'X', 'D', 'A', 'C', 'B'),\n",
      " ('Y', 'X', 'D', 'B', 'A', 'C'),\n",
      " ('Y', 'X', 'D', 'B', 'C', 'A'),\n",
      " ('Y', 'X', 'D', 'C', 'A', 'B'),\n",
      " ('Y', 'X', 'D', 'C', 'B', 'A')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from pprint import pprint\n",
    "\n",
    "# Use itertools permutations to get all possible orders of both blocks and localizers\n",
    "block_order = list(itertools.permutations(\"ABCD\"))\n",
    "loc_order = list(itertools.permutations(\"XY\"))\n",
    "\n",
    "# Repeat all elements in loc_orders to match sizes\n",
    "loc_order = [item for item in loc_order for i in range(len(block_order))]\n",
    "\n",
    "# Merge localizer and blocks\n",
    "block_order = [(x[0], x[1], y[0], y[1], y[2], y[3]) for x, y in zip(loc_order, block_order*2)]\n",
    "pprint(block_order)\n",
    "len(block_order)  # 48 possible conditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over participant numbers to generate the correct blocks in order, and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_localizer = 20  # In total! So currently, 10 'hand' trials and 10 'eye' trials\n",
    "n_trials_blocks = 96\n",
    "n_participants = 48\n",
    "n_null_trials_each_block = 9\n",
    "\n",
    "for pp in range(1, n_participants+1):\n",
    "    pp_str = str(pp).zfill(3)\n",
    "    block_order_this_pp = block_order[pp % len(block_order)]\n",
    "    \n",
    "    # Empty DataFrame\n",
    "    design_this_pp = pd.DataFrame()\n",
    "    \n",
    "    # Get blocks\n",
    "    for block_number, block_char in enumerate(block_order_this_pp):\n",
    "        if block_char == 'X':\n",
    "            block_data = create_localizer_block_single_effector(n_trials=n_trials_localizer/2, \n",
    "                                                                response_modality='hand',\n",
    "                                                                block_number=0,\n",
    "                                                                pseudorandomize=True)\n",
    "        elif block_char == 'Y':\n",
    "            block_data = create_localizer_block_single_effector(n_trials=n_trials_localizer/2, \n",
    "                                                                response_modality='eye',\n",
    "                                                                block_number=0,\n",
    "                                                                pseudorandomize=True)\n",
    "        elif block_char == 'A':\n",
    "            block_data = create_cognitive_block(n_trials=n_trials_blocks, \n",
    "                                                block_number=block_number-1, \n",
    "                                                response_modality='hand',\n",
    "                                                n_null_trials=n_null_trials_each_block)\n",
    "        elif block_char == 'B':\n",
    "            block_data = create_cognitive_block(n_trials=n_trials_blocks, \n",
    "                                                block_number=block_number-1, \n",
    "                                                response_modality='eye',\n",
    "                                                n_null_trials=n_null_trials_each_block)\n",
    "        elif block_char == 'C':\n",
    "            block_data = create_limbic_block(n_trials=n_trials_blocks, \n",
    "                                             block_number=block_number-1, \n",
    "                                             response_modality='hand',\n",
    "                                             n_null_trials=n_null_trials_each_block)\n",
    "        elif block_char == 'D':\n",
    "            block_data = create_limbic_block(n_trials=n_trials_blocks, \n",
    "                                             block_number=block_number-1, \n",
    "                                             response_modality='eye',\n",
    "                                             n_null_trials=n_null_trials_each_block)\n",
    "        \n",
    "        design_this_pp = design_this_pp.append(block_data)\n",
    "\n",
    "    # Set indices\n",
    "    design_this_pp.index.name = 'block_trial_ID'\n",
    "    design_this_pp.reset_index(inplace=True)\n",
    "    design_this_pp.index.name = 'trial_ID'\n",
    "    \n",
    "    # Add trial start times (relative to start of experiment)\n",
    "    design_this_pp['trial_start_time'] = design_this_pp['trial_duration'].shift(1).cumsum()\n",
    "    design_this_pp.loc[0, 'trial_start_time'] = 0\n",
    "\n",
    "    # Add cue onset times (relative to start of experiment)\n",
    "    design_this_pp['cue_onset_time'] = design_this_pp['trial_start_time'] + \\\n",
    "                                       design_this_pp['phase_1']\n",
    "\n",
    "    # Add stimulus onset times (relative to start of experiment)\n",
    "    design_this_pp['stimulus_onset_time'] = design_this_pp['trial_start_time'] + \\\n",
    "                                            design_this_pp['phase_1'] + \\\n",
    "                                            design_this_pp['phase_2'] + \\\n",
    "                                            design_this_pp['phase_3']\n",
    "    \n",
    "    # Re-order column order for nicety\n",
    "    design_this_pp = design_this_pp[['block_trial_ID', 'block', 'block_type', 'null_trial', 'correct_answer', 'cue', 'response_modality', 'trial_type', \n",
    "                                     'phase_0', 'phase_1', 'phase_2', 'phase_3', 'phase_4', 'phase_5', 'phase_6', 'phase_7', 'trial_duration', \n",
    "                                     'trial_start_time', 'cue_onset_time', 'stimulus_onset_time',\n",
    "                                     'trial_start_time_block', 'cue_onset_time_block', 'stimulus_onset_time_block']]\n",
    "    \n",
    "    # Save full data\n",
    "    if not os.path.exists(os.path.join('pp_%s' % pp_str, 'all_blocks')):\n",
    "        os.makedirs(os.path.join('pp_%s' % pp_str, 'all_blocks'))\n",
    "    design_this_pp.to_csv(os.path.join('pp_%s' % pp_str, 'all_blocks', 'trials.csv'), index=True)\n",
    "    \n",
    "    # Save individual blocks\n",
    "    for block_num, block_type in zip(design_this_pp['block'].unique(), design_this_pp['block_type'].unique()):\n",
    "        block = design_this_pp.loc[design_this_pp['block'] == block_num]\n",
    "        \n",
    "        if not os.path.exists(os.path.join('pp_%s' % pp_str, 'block_%d_type_%s' % (block_num, block_type))):\n",
    "            os.makedirs(os.path.join('pp_%s' % pp_str, 'block_%d_type_%s' % (block_num, block_type)))\n",
    "        \n",
    "        block.to_csv(os.path.join('pp_%s' % pp_str, 'block_%d_type_%s' % (block_num, block_type), 'trials.csv'), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create EV .txts files that can be read by FSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pp_num in range(1, 49):\n",
    "    pp_str = str(pp_num).zfill(3)\n",
    "    \n",
    "    for pp_block_dir in glob('pp_%s/*' % pp_str):\n",
    "        output_dir = os.path.join(pp_block_dir, 'evs')\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        design = pd.read_csv(os.path.join(pp_block_dir, 'trials.csv'))\n",
    "        design = design[['correct_answer','trial_type', 'block', 'phase_2', 'phase_4', 'cue', 'cue_onset_time', 'stimulus_onset_time', 'response_modality', 'null_trial']]\n",
    "        \n",
    "        # Get rid of all null trials\n",
    "        design = design.loc[design['null_trial'] != True]\n",
    "        \n",
    "        design['weight'] = 1\n",
    "        for cue_type in design['cue'].unique():\n",
    "            # Get cue onset time, cue duration, and cue weight\n",
    "            ev = design.loc[(design['cue'] == cue_type), ['cue_onset_time', 'phase_2', 'weight']].values.tolist()\n",
    "\n",
    "            with open(os.path.join(output_dir, 'ev_cue_%s.txt' % cue_type), 'wb') as f:\n",
    "                for _list in ev:\n",
    "                    for _string in _list:\n",
    "                        f.write(str(_string) + '\\n')\n",
    "                    f.write('\\n')\n",
    "\n",
    "        for stim_type in design['correct_answer'].unique():\n",
    "            if np.isnan(stim_type):  # a nan stimtype corresponds to a null trial\n",
    "                continue\n",
    "\n",
    "            for cue_type in design['cue'].unique():\n",
    "                # Gets stimulus onset time, stimulus duration, and weight\n",
    "                ev = design.loc[(design['correct_answer'] == stim_type) &\n",
    "                                (design['cue'] == cue_type), \n",
    "                                ['stimulus_onset_time', 'phase_4', 'weight']].values.tolist()\n",
    "\n",
    "                with open(os.path.join(output_dir, 'ev_stimulus_%d_%s.txt' % (stim_type, cue_type)), 'wb') as f:\n",
    "                    for _list in ev:\n",
    "                        for _string in _list:\n",
    "                            f.write(str(_string) + '\\n')\n",
    "                        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load FSL design text file for pp 1, and create for all other pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pp_001/all_blocks/design.fsf', 'rb') as f:\n",
    "    fsf_templ = f.readlines()\n",
    "\n",
    "for pp in range(2, 49):\n",
    "    fsf_thispp = copy.copy(fsf_templ)\n",
    "    \n",
    "    for i, line in enumerate(fsf_thispp):\n",
    "        fsf_thispp[i] = re.sub('pp_001', 'pp_' + str(pp).zfill(3), line)\n",
    "\n",
    "    with open('pp_%s/all_blocks/design.fsf' % str(pp).zfill(3), 'wb') as f:\n",
    "        f.writelines(fsf_thispp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_localizer_block(n_trials, block_number=None, response_modality=None, add_timing=True, pseudorandomize=True):\n",
    "    \"\"\"\n",
    "    Creates a block of localizer trials, with mixing both hand and eye trials\n",
    "    \"\"\"\n",
    "    trial_types = np.hstack((np.repeat([0, 1], repeats=n_trials/4),   # Eye cue, left/right\n",
    "                             np.repeat([2, 3], repeats=n_trials/4)))  # Hand cue, left/right\n",
    "    \n",
    "    # Initialize arrays\n",
    "    cue_by_trial = np.zeros(n_trials, dtype='<U5')\n",
    "    correct_answers = np.zeros(n_trials, dtype=np.int8)\n",
    "\n",
    "    # Define the cues for every trial\n",
    "    cue_by_trial[(trial_types == 0) | (trial_types == 1)] = 'EYE'\n",
    "    cue_by_trial[(trial_types == 2) | (trial_types == 3)] = 'HAND'\n",
    "\n",
    "    # Define the responses ('correct answers')/directions for every trial\n",
    "    correct_answers[(trial_types == 0) | (trial_types == 2)] = 0  # 0 = respond LEFT\n",
    "    correct_answers[(trial_types == 1) | (trial_types == 3)] = 1  # 1 = respond RIGHT\n",
    "    \n",
    "    # Create dataframe for eas ier handling\n",
    "    trial_data = pd.DataFrame({'correct_answer': correct_answers,\n",
    "                               'cue': cue_by_trial,\n",
    "                               'trial_type': trial_types})\n",
    "    \n",
    "    # Should we pseudorandomize?\n",
    "    if pseudorandomize:\n",
    "        trial_data = Pseudorandomizer(trial_data, max_identical_iters={'correct_answer': 4}).run()\n",
    "    \n",
    "    # Add block number for completeness\n",
    "    if block_number is not None:\n",
    "        trial_data['block'] = block_number\n",
    "        trial_data['block_type'] = 'localizer'\n",
    "\n",
    "    if add_timing:\n",
    "        trial_data = get_block_timing(trial_data, phase_2=1, phase_6=0)\n",
    "    \n",
    "    trial_data['response_modality'] = trial_data['cue'].str.lower()\n",
    "    \n",
    "    return trial_data"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
