{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "from pprint import pprint\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to generate blocks of trials\n",
    "Localizer, cognitive, and limbic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_localizer_block_single_effector_type2(n_trials, response_modality='eye', \n",
    "                                                 block_number=None, pseudorandomize=True, \n",
    "                                                 add_timing=True, null_trials=0, TR=2):\n",
    "    \n",
    "    # Only two trial types here: 'left' is correct, or 'right' is correct\n",
    "    trial_types = np.hstack((np.repeat([0, 1], repeats=n_trials / 4),   # Pro-saccadic cue, left/right corr\n",
    "                             np.repeat([2, 3], repeats=n_trials / 4)))  # Anti-saccadic cue, left/right corr\n",
    "    \n",
    "    # Initialize arrays\n",
    "    cue_by_trial = np.zeros(n_trials, dtype='<U10')\n",
    "    correct_answers = np.zeros(n_trials, dtype=np.int8)\n",
    "\n",
    "    # Define the cues for every trial\n",
    "    cue_by_trial[(trial_types == 0)] = 'pro_LEFT'\n",
    "    cue_by_trial[(trial_types == 1)] = 'pro_RIGHT'\n",
    "    cue_by_trial[(trial_types == 2)] = 'anti_LEFT'\n",
    "    cue_by_trial[(trial_types == 3)] = 'anti_RIGHT'\n",
    "\n",
    "    # Define the responses ('correct answers')/directions for every trial\n",
    "    correct_answers[(trial_types == 0) | (trial_types == 2)] = 0  # 0 = respond LEFT\n",
    "    correct_answers[(trial_types == 1) | (trial_types == 3)] = 1  # 1 = respond RIGHT\n",
    "    \n",
    "    # Create dataframe for easier handling\n",
    "    trial_data = pd.DataFrame({'correct_answer': correct_answers,\n",
    "                               'cue': cue_by_trial,\n",
    "                               'trial_type': trial_types})\n",
    "    \n",
    "    # Should we pseudorandomize?\n",
    "    if pseudorandomize:\n",
    "        trial_data = Pseudorandomizer(trial_data, max_identical_iters={'correct_answer': 3,\n",
    "                                                                       'cue': 3}).run()\n",
    "    \n",
    "    trial_data['null_trial'] = False\n",
    "    if null_trials > 0:\n",
    "        trial_data = add_pseudorandom_null_trials(trial_data, n_null_trials=null_trials)\n",
    "    \n",
    "    # Add block number for completeness\n",
    "    if block_number is not None:\n",
    "        trial_data['block'] = block_number\n",
    "        trial_data['block_type'] = 'localizer'\n",
    "\n",
    "    # Usually, we also want to add the duration of all the 'trial phases'\n",
    "    if add_timing:\n",
    "        # Set phase_3 and phase_0 to 0 (no post-cue fixcross, no feedback)\n",
    "        trial_data = get_localizer_timing(trial_data, TR=TR)\n",
    "#         trial_data['response_duration'] = 1.5\n",
    "    \n",
    "    trial_data['response_modality'] = response_modality.lower()\n",
    "    \n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_localizer_block_single_effector(n_trials, response_modality='eye', \n",
    "                                           block_number=None, pseudorandomize=True, \n",
    "                                           add_timing=True, null_trials=0, TR=2):\n",
    "    \n",
    "    # Only two trial types here: 'left' is correct, or 'right' is correct\n",
    "    trial_types = np.repeat([0, 1], repeats=n_trials/2)  # left/right\n",
    "#     trial_types = np.hstack((np.repeat([0, 1], repeats=n_trials / 4),   # Pro-saccadic cue, left/right corr\n",
    "#                              np.repeat([2, 3], repeats=n_trials / 4)))  # Anti-saccadic cue, left/right corr\n",
    "    \n",
    "    # Initialize arrays\n",
    "    cue_by_trial = np.zeros(n_trials, dtype='<U5')\n",
    "    correct_answers = np.zeros(n_trials, dtype=np.int8)\n",
    "\n",
    "    # Define the cues for every trial\n",
    "    cue_by_trial[(trial_types == 0)] = 'LEFT'\n",
    "    cue_by_trial[(trial_types == 1)] = 'RIGHT'\n",
    "#     cue_by_trial[(trial_types == 2) | (trial_types == 3)] = 'anti'\n",
    "\n",
    "    # Define the responses ('correct answers')/directions for every trial\n",
    "    correct_answers[trial_types == 0] = 0\n",
    "    correct_answers[trial_types == 1] = 1\n",
    "#     correct_answers[(trial_types == 0) | (trial_types == 2)] = 0  # 0 = respond LEFT\n",
    "#     correct_answers[(trial_types == 1) | (trial_types == 3)] = 1  # 1 = respond RIGHT\n",
    "    \n",
    "    # Create dataframe for easier handling\n",
    "    trial_data = pd.DataFrame({'correct_answer': correct_answers,\n",
    "                               'cue': cue_by_trial,\n",
    "                               'trial_type': trial_types})\n",
    "    \n",
    "    # Should we pseudorandomize?\n",
    "    if pseudorandomize:\n",
    "        trial_data = Pseudorandomizer(trial_data, max_identical_iters={'correct_answer': 3,\n",
    "                                                                       'cue': 3}).run()\n",
    "    \n",
    "    trial_data['null_trial'] = False\n",
    "    if null_trials > 0:\n",
    "        trial_data = add_pseudorandom_null_trials(trial_data, n_null_trials=null_trials)\n",
    "    \n",
    "    # Add block number for completeness\n",
    "    if block_number is not None:\n",
    "        trial_data['block'] = block_number\n",
    "        trial_data['block_type'] = 'localizer'\n",
    "\n",
    "    # Usually, we also want to add the duration of all the 'trial phases'\n",
    "    if add_timing:\n",
    "        # Set phase_3 and phase_0 to 0 (no post-cue fixcross, no feedback)\n",
    "        trial_data = get_localizer_timing(trial_data, TR=TR)\n",
    "    \n",
    "    trial_data['response_modality'] = response_modality.lower()\n",
    "    \n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cognitive_block(n_trials, block_number=None, response_modality=None, \n",
    "                           add_timing=True, pseudorandomize=True, n_null_trials=0, TR=2):\n",
    "    \"\"\"\n",
    "    Creates a block of SAT-trials; mixing speed and accuracy trials\n",
    "    \"\"\"\n",
    "    \n",
    "    trial_types = np.hstack((np.repeat([0, 1], repeats=n_trials / 4),   # SPEED cue, left/right corr\n",
    "                             np.repeat([2, 3], repeats=n_trials / 4)))  # ACCURACY cue, left/right corr\n",
    "\n",
    "    if trial_types.shape[0] != n_trials:\n",
    "        raise(ValueError('The provided n_trials (%d) could not be split into the correct number of trial types. '\n",
    "                         'Closest option is %d trials' % (n_trials, trial_types.shape[0])))\n",
    "\n",
    "    cue_by_trial = np.zeros(n_trials, dtype='<U5')\n",
    "    correct_answers = np.zeros(n_trials, dtype=np.int8)\n",
    "\n",
    "    cue_by_trial[(trial_types == 0) | (trial_types == 1)] = 'SPD'\n",
    "    cue_by_trial[(trial_types == 2) | (trial_types == 3)] = 'ACC'\n",
    "\n",
    "    correct_answers[(trial_types == 0) | (trial_types == 2)] = 0  # 0 = left is correct\n",
    "    correct_answers[(trial_types == 1) | (trial_types == 3)] = 1  # 1 = right is correct\n",
    "\n",
    "    # Create dataframe for easier handling\n",
    "    trial_data = pd.DataFrame({'correct_answer': correct_answers,\n",
    "                               'cue': cue_by_trial,\n",
    "                               'trial_type': trial_types})\n",
    "    \n",
    "    if pseudorandomize:\n",
    "        trial_data = Pseudorandomizer(trial_data, \n",
    "                                      max_identical_iters={'cue': 4, 'correct_answer': 4}).run()\n",
    "        \n",
    "    if n_null_trials > 0:\n",
    "        trial_data['null_trial'] = False\n",
    "        trial_data = add_pseudorandom_null_trials(trial_data, \n",
    "                                                  n_null_trials=n_null_trials, \n",
    "                                                  null_column_name='null_trial')\n",
    "\n",
    "    if block_number is not None:\n",
    "        trial_data['block'] = block_number\n",
    "        \n",
    "    if response_modality is not None:\n",
    "        trial_data['response_modality'] = response_modality\n",
    "        trial_data['block_type'] = 'cognitive_%s' % response_modality \n",
    "\n",
    "    if add_timing:\n",
    "        trial_data = get_block_timing(trial_data, TR=TR)  # Add default timing\n",
    "        \n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_limbic_block(n_trials, subject_number=1, block_number=None, \n",
    "                        response_modality=None, add_timing=True, pseudorandomize=True,\n",
    "                        n_null_trials=0, TR=2):\n",
    "    \n",
    "    trial_types = np.hstack((np.repeat([0, 1], repeats=n_trials/6),    # Neutral cue, left/right corr\n",
    "                             np.repeat([2, 3], repeats=n_trials/6),    # Left cue, left/right corr\n",
    "                             np.repeat([4, 5], repeats=n_trials/6)))   # Right cue, left/right corr\n",
    "\n",
    "    if trial_types.shape[0] != n_trials:\n",
    "        raise(ValueError('The provided n_trials (%d) could not be split into the correct number of trial types. '\n",
    "                     'Closest option is %d trials' % (n_trials, trial_types.shape[0])))\n",
    "\n",
    "    cue_by_trial = np.zeros(n_trials, dtype='<U5')\n",
    "    correct_answers = np.zeros(n_trials, dtype=np.int8)\n",
    "\n",
    "    cue_by_trial[(trial_types == 0) | (trial_types == 1)] = 'NEU'\n",
    "    cue_by_trial[(trial_types == 2) | (trial_types == 3)] = 'LEFT'\n",
    "    cue_by_trial[(trial_types == 4) | (trial_types == 5)] = 'RIGHT'\n",
    "\n",
    "    correct_answers[(trial_types == 0) |\n",
    "                    (trial_types == 2) |\n",
    "                    (trial_types == 4)] = 0  # 0 = left is correct\n",
    "    correct_answers[(trial_types == 1) |\n",
    "                    (trial_types == 3) |\n",
    "                    (trial_types == 5)] = 1  # 1 = right is correct\n",
    "\n",
    "    # Create dataframe for easier handling\n",
    "    trial_data = pd.DataFrame({'correct_answer': correct_answers,\n",
    "                               'cue': cue_by_trial,\n",
    "                               'trial_type': trial_types})\n",
    "\n",
    "    if pseudorandomize:\n",
    "        trial_data = Pseudorandomizer(trial_data, \n",
    "                                      max_identical_iters={'cue': 4, 'correct_answer': 4}).run()\n",
    "    \n",
    "    if n_null_trials > 0:\n",
    "        trial_data['null_trial'] = False\n",
    "        trial_data = add_pseudorandom_null_trials(trial_data, \n",
    "                                                  n_null_trials=n_null_trials, \n",
    "                                                  null_column_name='null_trial')\n",
    "    \n",
    "    if block_number is not None:\n",
    "        trial_data['block'] = block_number\n",
    "        \n",
    "    if response_modality is not None:\n",
    "        trial_data['response_modality'] = response_modality\n",
    "        trial_data['block_type'] = 'limbic_%s' % response_modality \n",
    "\n",
    "    if add_timing:\n",
    "        trial_data = get_block_timing(trial_data, TR=TR)  # Add default timing\n",
    "\n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that creates timing columns for a block of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_localizer_timing(trial_data, phase_0=None, phase_1=None, phase_2=None, phase_3=None, phase_4=None, phase_5=None, phase_6=None, TR=2):\n",
    "    \"\"\"\n",
    "    Each localizer trial consists of 7 phases.\n",
    "    \n",
    "    In phase_0, we wait for the scanner pulse. Note that phase_0 of trial n is the ITI after trial n-1. Set this timing always to 0: it is the `minimum` time to wait for the pulse\n",
    "    In phase_1, we show the pre-cue fixation cross. By default, timing is jittered (0s, 0.5s, 1s, 1.5s if TR=2 -- 0, .75, 1.5, 2.25 if TR=3).\n",
    "    In phase_2, we show the cue. Defaults to 1.5 second.\n",
    "    In phase_3, we show the post-cue fixation cross. Defaults to 0s.\n",
    "    In phase_4, we assume the participant responds, and wait a bit until we show the fix cross. Defaults to 0.6s\n",
    "    In phase_5 and phase_6, we do nothing (exist for compatibility with the experimental blocks)\n",
    "    Phase_7 is ITI\n",
    "    \"\"\"\n",
    "    \n",
    "    if TR == 2:\n",
    "        trial_data['phase_0'] = 0 if phase_0 is None else phase_0\n",
    "        trial_data['phase_1'] = np.random.choice([0.2, .7, 1.2, 1.7], size=trial_data.shape[0]) if phase_1 is None else phase_1\n",
    "        trial_data['phase_2'] = 0.8 if phase_2 is None else phase_2\n",
    "        trial_data['phase_3'] = 0 if phase_3 is None else phase_3\n",
    "        trial_data['phase_4'] = 0.6 if phase_4 is None else phase_4\n",
    "        trial_data['phase_5'] = 0 if phase_5 is None else phase_5\n",
    "        trial_data['phase_6'] = 0 if phase_6 is None else phase_6\n",
    "    elif TR == 3:\n",
    "        trial_data['phase_0'] = 0 if phase_0 is None else phase_0\n",
    "        trial_data['phase_1'] = np.random.choice([0, .750, 1.500, 2.250], size=trial_data.shape[0]) if phase_1 is None else phase_1\n",
    "        trial_data['phase_2'] = 1 if phase_2 is None else phase_2\n",
    "        trial_data['phase_3'] = 0 if phase_3 is None else phase_3\n",
    "        trial_data['phase_4'] = 0.6 if phase_4 is None else phase_4\n",
    "        trial_data['phase_5'] = 0 if phase_5 is None else phase_5\n",
    "        trial_data['phase_6'] = 0 if phase_6 is None else phase_6\n",
    "\n",
    "    # Calculate duration of trial (depends on random, jittered durations of the fix cross)\n",
    "    trial_data['trial_duration'] = trial_data[['phase_' + str(x) for x in range(7)]].sum(axis=1)\n",
    "\n",
    "    # Because of TR = 2s, some trials can last 8 seconds, but most will last 10. Find trials with total time < 8 seconds\n",
    "    # We calculate the ITI as the difference between the minimum number of pulses necessary for all phases to show.\n",
    "    # [same applies to TR = 3]\n",
    "#     min_TRs = np.ceil(trial_data['trial_duration'].values / TR)\n",
    "#     trial_data['phase_7'] = min_TRs*TR - trial_data['trial_duration'].values\n",
    "    trial_data['phase_7'] = 6 - trial_data['trial_duration'].values\n",
    "\n",
    "    # Recalculate trial duration so it includes the ITI\n",
    "    trial_data['trial_duration'] = trial_data[['phase_' + str(x) for x in range(8)]].sum(axis=1)\n",
    "\n",
    "    # Add trial start times relative to start of block\n",
    "    trial_data['trial_start_time_block'] = trial_data['trial_duration'].shift(1).cumsum()\n",
    "    trial_data.loc[0, 'trial_start_time_block'] = 0\n",
    "\n",
    "    # Add cue onset times relative to start of block\n",
    "    trial_data['cue_onset_time_block'] = trial_data['trial_start_time_block'] + \\\n",
    "                                         trial_data['phase_1']\n",
    "\n",
    "    # Add stimulus onset times relative to start of block\n",
    "    trial_data['stimulus_onset_time_block'] = trial_data['trial_start_time_block'] + \\\n",
    "                                              trial_data['phase_1'] + \\\n",
    "                                              trial_data['phase_2'] + \\\n",
    "                                              trial_data['phase_3']\n",
    "    return trial_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_timing(trial_data, phase_0=None, phase_1=None, phase_2=None, phase_3=None, phase_4=None, phase_5=None, phase_6=None, TR=2):\n",
    "    \"\"\"\n",
    "    Each trial consists of 7 phases.\n",
    "    \n",
    "    In phase_0, we wait for the scanner pulse. Note that phase_0 of trial n is the ITI after trial n-1. Set this timing always to 0: it is the `minimum` time to wait for the pulse\n",
    "    In phase_1, we show the pre-cue fixation cross. By default, timing is jittered (0s, 0.5s, 1s, 1.5s)\n",
    "    In phase_2, we show the cue. In decision-making trials, this is 4.8 seconds.\n",
    "    In phase_3, we show the post-cue fixation cross. Timing is jittered (0s, 0.5s, 1s, 1.5s)\n",
    "    In phase_4, we show the stimulus. Default is 1.5s.\n",
    "    Phase 5 is defined as the period of stimulus presentation, after the participant made a response. The duration is determined by the participant RT, so not set here.\n",
    "    In phase_6, we show feedback. Default is 0.35s.    \n",
    "    \"\"\"\n",
    "    \n",
    "    if TR == 2:\n",
    "        trial_data['phase_0'] = 0 if phase_0 is None else phase_0\n",
    "        trial_data['phase_1'] = np.random.choice([0, .5, 1, 1.5], size=trial_data.shape[0]) if phase_1 is None else phase_1\n",
    "        trial_data['phase_2'] = 4.8 if phase_2 is None else phase_2\n",
    "        trial_data['phase_3'] = np.random.choice([0, .5, 1, 1.5], size=trial_data.shape[0]) if phase_3 is None else phase_3\n",
    "        trial_data['phase_4'] = 1.5 if phase_4 is None else phase_4\n",
    "        trial_data['phase_5'] = 0 if phase_5 is None else phase_5\n",
    "        trial_data['phase_6'] = 0.35 if phase_6 is None else phase_6\n",
    "    elif TR == 3:\n",
    "        trial_data['phase_0'] = 0 if phase_0 is None else phase_0\n",
    "        trial_data['phase_1'] = np.random.choice([0, .750, 1.500, 2.250], size=trial_data.shape[0]) if phase_1 is None else phase_1\n",
    "        trial_data['phase_2'] = 1 if phase_2 is None else phase_2\n",
    "        trial_data['phase_3'] = np.random.choice([1.000, 1.750, 2.500, 3.250], size=trial_data.shape[0]) if phase_3 is None else phase_3\n",
    "        trial_data['phase_4'] = 1.5 if phase_4 is None else phase_4\n",
    "        trial_data['phase_5'] = 0 if phase_5 is None else phase_5\n",
    "        trial_data['phase_6'] = 0.5 if phase_6 is None else phase_6\n",
    "\n",
    "\n",
    "    # Calculate duration of trial (depends on random, jittered durations of the fix cross)\n",
    "    trial_data['trial_duration'] = trial_data[['phase_' + str(x) for x in range(7)]].sum(axis=1)\n",
    "\n",
    "    if TR == 2:\n",
    "        # Because of TR = 2s, some trials can last 8 seconds, but most will last 10. Find trials with total time < 8 seconds\n",
    "        # We calculate the ITI as the difference between the minimum number of pulses necessary for all phases to show.\n",
    "        min_TRs = np.ceil(trial_data['trial_duration'].values / TR)\n",
    "        trial_data['phase_7'] = min_TRs*TR - trial_data['trial_duration'].values\n",
    "    elif TR == 3:\n",
    "        # In this case, fill all trials until 9s have passed.\n",
    "        trial_data['phase_7'] = 9 - trial_data['trial_duration'].values\n",
    "\n",
    "    # Recalculate trial duration so it includes the ITI\n",
    "    trial_data['trial_duration'] = trial_data[['phase_' + str(x) for x in range(8)]].sum(axis=1)\n",
    "\n",
    "    # Add trial start times relative to start of block\n",
    "    trial_data['trial_start_time_block'] = trial_data['trial_duration'].shift(1).cumsum()\n",
    "    trial_data.loc[0, 'trial_start_time_block'] = 0\n",
    "\n",
    "    # Add cue onset times relative to start of block\n",
    "    trial_data['cue_onset_time_block'] = trial_data['trial_start_time_block'] + \\\n",
    "                                         trial_data['phase_1']\n",
    "\n",
    "    # Add stimulus onset times relative to start of block\n",
    "    trial_data['stimulus_onset_time_block'] = trial_data['trial_start_time_block'] + \\\n",
    "                                              trial_data['phase_1'] + \\\n",
    "                                              trial_data['phase_2'] + \\\n",
    "                                              trial_data['phase_3']\n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for pseudorandomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pseudorandomizer(object):\n",
    "    \n",
    "    def __init__(self, data, max_identical_iters={'cue': 4, 'correct_answer': 4}):  \n",
    "        self.data = data\n",
    "        self.max_identical_iters = {x: y+1 for x, y in max_identical_iters.items()}\n",
    "                                    # add 1: if 4 rows is allowed, only give an error after 5 identical rows\n",
    "    \n",
    "    def check_trial_rows(self, data, row_n): \n",
    "        \"\"\"\n",
    "        Returns True if any of the conditions for pseudorandomization are violated for the given rows, \n",
    "        False if they are fine.\n",
    "        \"\"\"\n",
    "        \n",
    "        # First, check for the maximum iterations\n",
    "        for column, max_iter in self.max_identical_iters.items():\n",
    "            if row_n - max_iter < 0:\n",
    "                continue\n",
    "\n",
    "            # Select rows [max_iter-1 - row_n] we're going to check. Never select any row with index < 0\n",
    "            row_selection = [x for x in np.arange(row_n, row_n-max_iter, -1)]\n",
    "\n",
    "            # Next, we check if the selected rows only contain *1* trial type. \n",
    "            # If so, this means we have max_iter rows of the same trials, and we need to change something.\n",
    "            if data.iloc[row_selection][column].nunique() == 1:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def run(self, debug=False):\n",
    "        \"\"\"\n",
    "        Pseudorandomizes: makes sure that it is not possible to have more than x iterations for every type of column, specified in columns.\n",
    "        \"\"\"\n",
    "        # Start by copying from original data, and shuffle\n",
    "        self.data = self.data.sample(frac=1, \n",
    "                                     random_state=np.random.randint(0, 1e7, dtype='int')).reset_index(drop=True) \n",
    "        \n",
    "        if debug:\n",
    "            outer_while_i = 0\n",
    "            debug_print_after_i = 100\n",
    "\n",
    "        good_set = False\n",
    "        while not good_set:\n",
    "            if debug:\n",
    "                outer_while_i += 1\n",
    "\n",
    "            reshuffle = False  # Assume the dataset does not need reshuffling.\n",
    "            for row_n in range(0, self.data.shape[0]):\n",
    "\n",
    "                # Select rows [max_iter-1 - row_n] we're going to check\n",
    "\n",
    "                # Check if the current row, and the (max_iters-1) rows before, are the same value (number of unique values = 1).\n",
    "                # If so, then move the current row number to the bottom of the dataframe. However, we need to re-check the same four rows again\n",
    "                # after moving a row to the bottom: therefore, a while loop is necessary.\n",
    "                checked_row = False\n",
    "                n_attempts_at_moving = 0\n",
    "                \n",
    "                if debug:\n",
    "                    inner_while_i = 0\n",
    "                \n",
    "                while not checked_row:\n",
    "                    if debug:\n",
    "                        inner_while_i += 1\n",
    "                        if inner_while_i > debug_print_after_i:\n",
    "                            print('New inner loop started for current row')\n",
    "\n",
    "                    if self.check_trial_rows(self.data, row_n):\n",
    "                        if debug and inner_while_i > debug_print_after_i:\n",
    "                            print('Found too many consecutively identical rows.')\n",
    "\n",
    "                        # If there are too many consecutively identical rows at the bottom of the dataframe, \n",
    "                        # break and start over/shuffle\n",
    "                        if row_n >= (self.data.shape[0] - self.max_identical_iters[self.max_identical_iters.keys()[0]]):\n",
    "                            if debug and inner_while_i > debug_print_after_i:\n",
    "                                print('These occurred at row_n %d, which is at the bottom of the DF.' % row_n)\n",
    "\n",
    "                            checked_row = True\n",
    "                            reshuffle = True\n",
    "\n",
    "                        # Too many consecutive identical rows? Move row_n to the bottom, and check again with the new row_n.\n",
    "                        else:\n",
    "                            if debug and inner_while_i > debug_print_after_i:\n",
    "                                print('These occurred at row_n %d. Checking the remainder of the DF.' % row_n)\n",
    "\n",
    "                            # Check if moving to the bottom even makes sense: if all remaining values are identical, it doesn't.\n",
    "                            if (self.data.iloc[row_n:][self.max_identical_iters.keys()].nunique().values < 2).any():\n",
    "                                if debug and inner_while_i > debug_print_after_i:\n",
    "                                    print('All remaining values are identical. I should stop the for-loop, and start over.')\n",
    "\n",
    "                                checked_row = True\n",
    "                                reshuffle = True\n",
    "                            else:\n",
    "                                if n_attempts_at_moving < 50:\n",
    "                                    n_attempts_at_moving += 1\n",
    "\n",
    "                                    if debug and inner_while_i > debug_print_after_i:\n",
    "                                        print('Not all remaining values are identical. I should move the final part to the bottom.')\n",
    "\n",
    "                                    # If not, move the current row to the bottom\n",
    "                                    row_to_move = self.data.iloc[row_n,:]\n",
    "\n",
    "                                    # Delete row from df\n",
    "                                    self.data.drop(row_n, axis=0, inplace=True)\n",
    "\n",
    "                                    # Append original row to end. Make sure to reset index\n",
    "                                    self.data = self.data.append(row_to_move).reset_index(drop=True)\n",
    "\n",
    "                                # If we already tried moving the current row to the bottom for 50 times, let's forget about it and restart\n",
    "                                else:\n",
    "                                    checked_row = True\n",
    "                                    reshuffle = True\n",
    "                    else:\n",
    "                        if debug and inner_while_i > debug_print_after_i:\n",
    "                            print('Checked row, but the row is fine. Next row.')\n",
    "                        checked_row = True\n",
    "\n",
    "                if reshuffle:\n",
    "                    good_set = False\n",
    "                    break  # out of the for loop\n",
    "\n",
    "                # Reached the bottom of the dataframe, but no reshuffle call? Then we're set.\n",
    "                if row_n == self.data.shape[0]-1:\n",
    "                    good_set = True\n",
    "\n",
    "            if reshuffle:\n",
    "                # Shuffle, reset index to ensure trial_data.drop(row_n) rows\n",
    "                self.data = self.data.sample(frac=1, random_state=np.random.randint(0, 1e7, dtype='int')).reset_index(drop=True)\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "def add_pseudorandom_null_trials(data, min_row=4, max_row=4, min_n_rows_separate=7, \n",
    "                                n_null_trials=10, null_column_name=''):\n",
    "    \"\"\" \n",
    "    Adds null trials interspersed at pseudorandom locations. You can determine the minimum\n",
    "    number of trials at the start before a null trial, the minimum number of trials at the end in which no\n",
    "    nulls are shown, and the minimum number of trials that the null trials have to be separated \n",
    "    \"\"\"\n",
    "    \n",
    "    good_idx = False\n",
    "    while not good_idx:\n",
    "        indx = np.random.choice(np.arange(min_row, data.shape[0]-max_row), \n",
    "                                replace=False, size=n_null_trials)\n",
    "        diffs = np.diff(np.sort(indx))\n",
    "        if (diffs >= min_n_rows_separate).all():\n",
    "            good_idx = True\n",
    "    \n",
    "    data.index = np.setdiff1d(np.arange(data.shape[0] + n_null_trials), indx)\n",
    "    new_rows = pd.DataFrame({null_column_name: [True]*n_null_trials}, columns=data.columns, index=indx)\n",
    "    data = data.append(new_rows).sort_index()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order of blocks by participant\n",
    "\n",
    "- X = localizer hand\n",
    "- Y = localizer eye\n",
    "- A = cognitive, hand\n",
    "- B = cognitive, eye\n",
    "- C = limbic, hand\n",
    "- D = limbic, eye\n",
    "\n",
    "4 blocks, 4\\*3\\*2\\*1 = 4! = 24 block orders\n",
    "\n",
    "2 localizer 'blocks', 2\\*1 = 2 possible orders.\n",
    "In total, 48 possible block orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('X', 'Y', 'A', 'B', 'C', 'D'),\n",
      " ('X', 'Y', 'A', 'B', 'D', 'C'),\n",
      " ('X', 'Y', 'A', 'C', 'B', 'D'),\n",
      " ('X', 'Y', 'A', 'C', 'D', 'B'),\n",
      " ('X', 'Y', 'A', 'D', 'B', 'C'),\n",
      " ('X', 'Y', 'A', 'D', 'C', 'B'),\n",
      " ('X', 'Y', 'B', 'A', 'C', 'D'),\n",
      " ('X', 'Y', 'B', 'A', 'D', 'C'),\n",
      " ('X', 'Y', 'B', 'C', 'A', 'D'),\n",
      " ('X', 'Y', 'B', 'C', 'D', 'A'),\n",
      " ('X', 'Y', 'B', 'D', 'A', 'C'),\n",
      " ('X', 'Y', 'B', 'D', 'C', 'A'),\n",
      " ('X', 'Y', 'C', 'A', 'B', 'D'),\n",
      " ('X', 'Y', 'C', 'A', 'D', 'B'),\n",
      " ('X', 'Y', 'C', 'B', 'A', 'D'),\n",
      " ('X', 'Y', 'C', 'B', 'D', 'A'),\n",
      " ('X', 'Y', 'C', 'D', 'A', 'B'),\n",
      " ('X', 'Y', 'C', 'D', 'B', 'A'),\n",
      " ('X', 'Y', 'D', 'A', 'B', 'C'),\n",
      " ('X', 'Y', 'D', 'A', 'C', 'B'),\n",
      " ('X', 'Y', 'D', 'B', 'A', 'C'),\n",
      " ('X', 'Y', 'D', 'B', 'C', 'A'),\n",
      " ('X', 'Y', 'D', 'C', 'A', 'B'),\n",
      " ('X', 'Y', 'D', 'C', 'B', 'A'),\n",
      " ('Y', 'X', 'A', 'B', 'C', 'D'),\n",
      " ('Y', 'X', 'A', 'B', 'D', 'C'),\n",
      " ('Y', 'X', 'A', 'C', 'B', 'D'),\n",
      " ('Y', 'X', 'A', 'C', 'D', 'B'),\n",
      " ('Y', 'X', 'A', 'D', 'B', 'C'),\n",
      " ('Y', 'X', 'A', 'D', 'C', 'B'),\n",
      " ('Y', 'X', 'B', 'A', 'C', 'D'),\n",
      " ('Y', 'X', 'B', 'A', 'D', 'C'),\n",
      " ('Y', 'X', 'B', 'C', 'A', 'D'),\n",
      " ('Y', 'X', 'B', 'C', 'D', 'A'),\n",
      " ('Y', 'X', 'B', 'D', 'A', 'C'),\n",
      " ('Y', 'X', 'B', 'D', 'C', 'A'),\n",
      " ('Y', 'X', 'C', 'A', 'B', 'D'),\n",
      " ('Y', 'X', 'C', 'A', 'D', 'B'),\n",
      " ('Y', 'X', 'C', 'B', 'A', 'D'),\n",
      " ('Y', 'X', 'C', 'B', 'D', 'A'),\n",
      " ('Y', 'X', 'C', 'D', 'A', 'B'),\n",
      " ('Y', 'X', 'C', 'D', 'B', 'A'),\n",
      " ('Y', 'X', 'D', 'A', 'B', 'C'),\n",
      " ('Y', 'X', 'D', 'A', 'C', 'B'),\n",
      " ('Y', 'X', 'D', 'B', 'A', 'C'),\n",
      " ('Y', 'X', 'D', 'B', 'C', 'A'),\n",
      " ('Y', 'X', 'D', 'C', 'A', 'B'),\n",
      " ('Y', 'X', 'D', 'C', 'B', 'A')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from pprint import pprint\n",
    "\n",
    "# Use itertools permutations to get all possible orders of both blocks and localizers\n",
    "block_order = list(itertools.permutations(\"ABCD\"))\n",
    "loc_order = list(itertools.permutations(\"XY\"))\n",
    "\n",
    "# Repeat all elements in loc_orders to match sizes\n",
    "loc_order = [item for item in loc_order for i in range(len(block_order))]\n",
    "\n",
    "# Merge localizer and blocks\n",
    "block_order = [(x[0], x[1], y[0], y[1], y[2], y[3]) for x, y in zip(loc_order, block_order*2)]\n",
    "pprint(block_order)\n",
    "len(block_order)  # 48 possible conditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over participant numbers to generate the correct blocks in order, and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 12, 24, 36, 48, 60, 72, 84, 96, 108]\n"
     ]
    }
   ],
   "source": [
    "a = [x for x in range(120) if x % 4 == 0 and x % 6 == 0]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_trials_per_localizer_block = 8\n",
    "n_localizer_blocks = 6\n",
    "TR = 3\n",
    "\n",
    "n_trials_limbic = 84\n",
    "n_trials_cognitive = 72\n",
    "n_null_trials_limbic = 8\n",
    "n_null_trials_cognitive = 7\n",
    "n_participants = 2\n",
    "\n",
    "for pp in range(0, n_participants):\n",
    "    pp_str = str(pp+1).zfill(3)\n",
    "    block_order_this_pp = block_order[pp % len(block_order)]\n",
    "    \n",
    "    # Empty DataFrame\n",
    "    design_this_pp = pd.DataFrame()\n",
    "    \n",
    "    # Get localizer block\n",
    "    if block_order_this_pp[0] == 'X':\n",
    "        localizer_order = ['hand', 'eye']\n",
    "    else:\n",
    "        localizer_order = ['eye', 'hand']\n",
    "\n",
    "    for localizer_block in range(n_localizer_blocks/2):\n",
    "        block_data = pd.DataFrame()\n",
    "        for localizer_block in range(n_localizer_blocks/2):\n",
    "            loc_block = create_localizer_block_single_effector(n_trials=n_trials_per_localizer_block, \n",
    "                                                response_modality=localizer_order[0],\n",
    "                                                block_number=0,\n",
    "                                                pseudorandomize=True, TR=TR)\n",
    "            block_data = block_data.append(loc_block)\n",
    "            loc_block = create_localizer_block_single_effector(n_trials=n_trials_per_localizer_block, \n",
    "                                                response_modality=localizer_order[1],\n",
    "                                                block_number=0,\n",
    "                                                pseudorandomize=True, TR=TR)\n",
    "            block_data = block_data.append(loc_block)\n",
    "    design_this_pp = design_this_pp.append(block_data)\n",
    "\n",
    "    # Get blocks\n",
    "    for block_number, block_char in enumerate(block_order_this_pp):\n",
    "        if block_char in ['X', 'Y']:\n",
    "            continue\n",
    "        \n",
    "        if block_char == 'A':\n",
    "            block_data = create_cognitive_block(n_trials=n_trials_cognitive, \n",
    "                                                block_number=block_number-1, \n",
    "                                                response_modality='hand',\n",
    "                                                n_null_trials=n_null_trials_cognitive, \n",
    "                                                TR=TR)\n",
    "        elif block_char == 'B':\n",
    "            block_data = create_cognitive_block(n_trials=n_trials_cognitive, \n",
    "                                                block_number=block_number-1, \n",
    "                                                response_modality='eye',\n",
    "                                                n_null_trials=n_null_trials_cognitive,\n",
    "                                                TR=TR)\n",
    "        elif block_char == 'C':\n",
    "            block_data = create_limbic_block(n_trials=n_trials_limbic, \n",
    "                                             block_number=block_number-1, \n",
    "                                             response_modality='hand',\n",
    "                                             n_null_trials=n_null_trials_limbic,\n",
    "                                             TR=TR)\n",
    "        elif block_char == 'D':\n",
    "            block_data = create_limbic_block(n_trials=n_trials_limbic, \n",
    "                                             block_number=block_number-1, \n",
    "                                             response_modality='eye',\n",
    "                                             n_null_trials=n_null_trials_limbic,\n",
    "                                             TR=TR)\n",
    "        \n",
    "        design_this_pp = design_this_pp.append(block_data)\n",
    "\n",
    "    # Set indices\n",
    "    design_this_pp.index.name = 'block_trial_ID'\n",
    "    design_this_pp.reset_index(inplace=True)\n",
    "    design_this_pp.index.name = 'trial_ID'\n",
    "    \n",
    "    # Add trial start times (relative to start of experiment)\n",
    "    design_this_pp['trial_start_time'] = design_this_pp['trial_duration'].shift(1).cumsum()\n",
    "    design_this_pp.loc[0, 'trial_start_time'] = 0\n",
    "\n",
    "    # Add cue onset times (relative to start of experiment)\n",
    "    design_this_pp['cue_onset_time'] = design_this_pp['trial_start_time'] + \\\n",
    "                                       design_this_pp['phase_1']\n",
    "\n",
    "    # Add stimulus onset times (relative to start of experiment)\n",
    "    design_this_pp['stimulus_onset_time'] = design_this_pp['trial_start_time'] + \\\n",
    "                                            design_this_pp['phase_1'] + \\\n",
    "                                            design_this_pp['phase_2'] + \\\n",
    "                                            design_this_pp['phase_3']\n",
    "    \n",
    "    # Re-order column order for nicety\n",
    "    design_this_pp = design_this_pp[['block_trial_ID', 'block', 'block_type', 'null_trial', 'correct_answer', 'cue', 'response_modality', 'trial_type', \n",
    "                                     'phase_0', 'phase_1', 'phase_2', 'phase_3', 'phase_4', 'phase_5', 'phase_6', 'phase_7', 'trial_duration', \n",
    "                                     'trial_start_time', 'cue_onset_time', 'stimulus_onset_time',\n",
    "                                     'trial_start_time_block', 'cue_onset_time_block', 'stimulus_onset_time_block']]\n",
    "    \n",
    "    # Save full data\n",
    "    if not os.path.exists(os.path.join('pp_%s' % pp_str, 'all_blocks')):\n",
    "        os.makedirs(os.path.join('pp_%s' % pp_str, 'all_blocks'))\n",
    "    design_this_pp.to_csv(os.path.join('pp_%s' % pp_str, 'all_blocks', 'trials.csv'), index=True)\n",
    "    \n",
    "    # Save individual blocks\n",
    "    for block_num, block_type in zip(design_this_pp['block'].unique(), design_this_pp['block_type'].unique()):\n",
    "        block = design_this_pp.loc[design_this_pp['block'] == block_num]\n",
    "        \n",
    "        if not os.path.exists(os.path.join('pp_%s' % pp_str, 'block_%d_type_%s' % (block_num, block_type))):\n",
    "            os.makedirs(os.path.join('pp_%s' % pp_str, 'block_%d_type_%s' % (block_num, block_type)))\n",
    "        \n",
    "        block.to_csv(os.path.join('pp_%s' % pp_str, 'block_%d_type_%s' % (block_num, block_type), 'trials.csv'), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating EVs, .fsf-files, and running FSL\n",
    "All following code is used to transform the created designs into FSL-accepted formats. First, we create 3-column .txt-files for every regressor. Then, we *manually* and painfully make the .fsf file for a single subject (for all designs) in the FSL gui (if someone can point me to a CLI for this, I'd be very grateful).\n",
    "Finally, we copy the created .fsf-file and substitute all references to the first pp for each other pp.\n",
    "### Create EV .txts files that can be read by FSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pp 1...\n",
      "['pp_001/all_blocks', 'pp_001/block_0_type_localizer', 'pp_001/block_1_type_cognitive_hand', 'pp_001/block_2_type_cognitive_eye', 'pp_001/block_3_type_limbic_hand', 'pp_001/block_4_type_limbic_eye']\n",
      "Processing pp 2...\n",
      "['pp_002/all_blocks', 'pp_002/all_blocks.feat', 'pp_002/block_0_type_localizer', 'pp_002/block_0_type_localizer.feat', 'pp_002/block_1_type_cognitive_hand', 'pp_002/block_1_type_cognitive_hand.feat', 'pp_002/block_2_type_cognitive_eye', 'pp_002/block_2_type_cognitive_eye.feat', 'pp_002/block_3_type_limbic_eye', 'pp_002/block_3_type_limbic_eye.feat', 'pp_002/block_4_type_limbic_hand', 'pp_002/block_4_type_limbic_hand.feat']\n",
      "Processing pp 3...\n",
      "['pp_003/all_blocks', 'pp_003/block_0_type_localizer', 'pp_003/block_1_type_cognitive_hand', 'pp_003/block_2_type_limbic_hand', 'pp_003/block_3_type_cognitive_eye', 'pp_003/block_4_type_limbic_eye']\n",
      "Processing pp 4...\n",
      "['pp_004/all_blocks', 'pp_004/block_0_type_localizer', 'pp_004/block_1_type_cognitive_hand', 'pp_004/block_2_type_limbic_hand', 'pp_004/block_3_type_limbic_eye', 'pp_004/block_4_type_cognitive_eye']\n",
      "Processing pp 5...\n",
      "['pp_005/all_blocks', 'pp_005/block_0_type_localizer', 'pp_005/block_1_type_cognitive_hand', 'pp_005/block_2_type_limbic_eye', 'pp_005/block_3_type_cognitive_eye', 'pp_005/block_4_type_limbic_hand']\n",
      "Processing pp 6...\n",
      "['pp_006/all_blocks', 'pp_006/block_0_type_localizer', 'pp_006/block_1_type_cognitive_hand', 'pp_006/block_2_type_limbic_eye', 'pp_006/block_3_type_limbic_hand', 'pp_006/block_4_type_cognitive_eye']\n",
      "Processing pp 7...\n",
      "['pp_007/all_blocks', 'pp_007/block_0_type_localizer', 'pp_007/block_1_type_cognitive_eye', 'pp_007/block_2_type_cognitive_hand', 'pp_007/block_3_type_limbic_hand', 'pp_007/block_4_type_limbic_eye']\n",
      "Processing pp 8...\n",
      "['pp_008/all_blocks', 'pp_008/block_0_type_localizer', 'pp_008/block_1_type_cognitive_eye', 'pp_008/block_2_type_cognitive_hand', 'pp_008/block_3_type_limbic_eye', 'pp_008/block_4_type_limbic_hand']\n",
      "Processing pp 9...\n",
      "['pp_009/all_blocks', 'pp_009/block_0_type_localizer', 'pp_009/block_1_type_cognitive_eye', 'pp_009/block_2_type_limbic_hand', 'pp_009/block_3_type_cognitive_hand', 'pp_009/block_4_type_limbic_eye']\n",
      "Processing pp 10...\n",
      "['pp_010/all_blocks', 'pp_010/block_0_type_localizer', 'pp_010/block_1_type_cognitive_eye', 'pp_010/block_2_type_limbic_hand', 'pp_010/block_3_type_limbic_eye', 'pp_010/block_4_type_cognitive_hand']\n",
      "Processing pp 11...\n",
      "['pp_011/all_blocks', 'pp_011/block_0_type_localizer', 'pp_011/block_1_type_cognitive_eye', 'pp_011/block_2_type_limbic_eye', 'pp_011/block_3_type_cognitive_hand', 'pp_011/block_4_type_limbic_hand']\n",
      "Processing pp 12...\n",
      "['pp_012/all_blocks', 'pp_012/block_0_type_localizer', 'pp_012/block_1_type_cognitive_eye', 'pp_012/block_2_type_limbic_eye', 'pp_012/block_3_type_limbic_hand', 'pp_012/block_4_type_cognitive_hand']\n",
      "Processing pp 13...\n",
      "['pp_013/all_blocks', 'pp_013/block_0_type_localizer', 'pp_013/block_1_type_limbic_hand', 'pp_013/block_2_type_cognitive_hand', 'pp_013/block_3_type_cognitive_eye', 'pp_013/block_4_type_limbic_eye']\n",
      "Processing pp 14...\n",
      "['pp_014/all_blocks', 'pp_014/block_0_type_localizer', 'pp_014/block_1_type_limbic_hand', 'pp_014/block_2_type_cognitive_hand', 'pp_014/block_3_type_limbic_eye', 'pp_014/block_4_type_cognitive_eye']\n",
      "Processing pp 15...\n",
      "['pp_015/all_blocks', 'pp_015/block_0_type_localizer', 'pp_015/block_1_type_limbic_hand', 'pp_015/block_2_type_cognitive_eye', 'pp_015/block_3_type_cognitive_hand', 'pp_015/block_4_type_limbic_eye']\n",
      "Processing pp 16...\n",
      "['pp_016/all_blocks', 'pp_016/block_0_type_localizer', 'pp_016/block_1_type_limbic_hand', 'pp_016/block_2_type_cognitive_eye', 'pp_016/block_3_type_limbic_eye', 'pp_016/block_4_type_cognitive_hand']\n",
      "Processing pp 17...\n",
      "['pp_017/all_blocks', 'pp_017/block_0_type_localizer', 'pp_017/block_1_type_limbic_hand', 'pp_017/block_2_type_limbic_eye', 'pp_017/block_3_type_cognitive_hand', 'pp_017/block_4_type_cognitive_eye']\n",
      "Processing pp 18...\n",
      "['pp_018/all_blocks', 'pp_018/block_0_type_localizer', 'pp_018/block_1_type_limbic_hand', 'pp_018/block_2_type_limbic_eye', 'pp_018/block_3_type_cognitive_eye', 'pp_018/block_4_type_cognitive_hand']\n",
      "Processing pp 19...\n",
      "['pp_019/all_blocks', 'pp_019/block_0_type_localizer', 'pp_019/block_1_type_limbic_eye', 'pp_019/block_2_type_cognitive_hand', 'pp_019/block_3_type_cognitive_eye', 'pp_019/block_4_type_limbic_hand']\n",
      "Processing pp 20...\n",
      "['pp_020/all_blocks', 'pp_020/block_0_type_localizer', 'pp_020/block_1_type_limbic_eye', 'pp_020/block_2_type_cognitive_hand', 'pp_020/block_3_type_limbic_hand', 'pp_020/block_4_type_cognitive_eye']\n",
      "Processing pp 21...\n",
      "['pp_021/all_blocks', 'pp_021/block_0_type_localizer', 'pp_021/block_1_type_limbic_eye', 'pp_021/block_2_type_cognitive_eye', 'pp_021/block_3_type_cognitive_hand', 'pp_021/block_4_type_limbic_hand']\n",
      "Processing pp 22...\n",
      "['pp_022/all_blocks', 'pp_022/block_0_type_localizer', 'pp_022/block_1_type_limbic_eye', 'pp_022/block_2_type_cognitive_eye', 'pp_022/block_3_type_limbic_hand', 'pp_022/block_4_type_cognitive_hand']\n",
      "Processing pp 23...\n",
      "['pp_023/all_blocks', 'pp_023/block_0_type_localizer', 'pp_023/block_1_type_limbic_eye', 'pp_023/block_2_type_limbic_hand', 'pp_023/block_3_type_cognitive_hand', 'pp_023/block_4_type_cognitive_eye']\n",
      "Processing pp 24...\n",
      "['pp_024/all_blocks', 'pp_024/block_0_type_localizer', 'pp_024/block_1_type_limbic_eye', 'pp_024/block_2_type_limbic_hand', 'pp_024/block_3_type_cognitive_eye', 'pp_024/block_4_type_cognitive_hand']\n",
      "Processing pp 25...\n",
      "['pp_025/all_blocks', 'pp_025/block_0_type_localizer', 'pp_025/block_1_type_cognitive_hand', 'pp_025/block_2_type_cognitive_eye', 'pp_025/block_3_type_limbic_hand', 'pp_025/block_4_type_limbic_eye']\n",
      "Processing pp 26...\n",
      "['pp_026/all_blocks', 'pp_026/block_0_type_localizer', 'pp_026/block_1_type_cognitive_hand', 'pp_026/block_2_type_cognitive_eye', 'pp_026/block_3_type_limbic_eye', 'pp_026/block_4_type_limbic_hand']\n",
      "Processing pp 27...\n",
      "['pp_027/all_blocks', 'pp_027/block_0_type_localizer', 'pp_027/block_1_type_cognitive_hand', 'pp_027/block_2_type_limbic_hand', 'pp_027/block_3_type_cognitive_eye', 'pp_027/block_4_type_limbic_eye']\n",
      "Processing pp 28...\n",
      "['pp_028/all_blocks', 'pp_028/block_0_type_localizer', 'pp_028/block_1_type_cognitive_hand', 'pp_028/block_2_type_limbic_hand', 'pp_028/block_3_type_limbic_eye', 'pp_028/block_4_type_cognitive_eye']\n",
      "Processing pp 29...\n",
      "['pp_029/all_blocks', 'pp_029/block_0_type_localizer', 'pp_029/block_1_type_cognitive_hand', 'pp_029/block_2_type_limbic_eye', 'pp_029/block_3_type_cognitive_eye', 'pp_029/block_4_type_limbic_hand']\n",
      "Processing pp 30...\n",
      "['pp_030/all_blocks', 'pp_030/block_0_type_localizer', 'pp_030/block_1_type_cognitive_hand', 'pp_030/block_2_type_limbic_eye', 'pp_030/block_3_type_limbic_hand', 'pp_030/block_4_type_cognitive_eye']\n",
      "Processing pp 31...\n",
      "['pp_031/all_blocks', 'pp_031/block_0_type_localizer', 'pp_031/block_1_type_cognitive_eye', 'pp_031/block_2_type_cognitive_hand', 'pp_031/block_3_type_limbic_hand', 'pp_031/block_4_type_limbic_eye']\n",
      "Processing pp 32...\n",
      "['pp_032/all_blocks', 'pp_032/block_0_type_localizer', 'pp_032/block_1_type_cognitive_eye', 'pp_032/block_2_type_cognitive_hand', 'pp_032/block_3_type_limbic_eye', 'pp_032/block_4_type_limbic_hand']\n",
      "Processing pp 33...\n",
      "['pp_033/all_blocks', 'pp_033/block_0_type_localizer', 'pp_033/block_1_type_cognitive_eye', 'pp_033/block_2_type_limbic_hand', 'pp_033/block_3_type_cognitive_hand', 'pp_033/block_4_type_limbic_eye']\n",
      "Processing pp 34...\n",
      "['pp_034/all_blocks', 'pp_034/block_0_type_localizer', 'pp_034/block_1_type_cognitive_eye', 'pp_034/block_2_type_limbic_hand', 'pp_034/block_3_type_limbic_eye', 'pp_034/block_4_type_cognitive_hand']\n",
      "Processing pp 35...\n",
      "['pp_035/all_blocks', 'pp_035/block_0_type_localizer', 'pp_035/block_1_type_cognitive_eye', 'pp_035/block_2_type_limbic_eye', 'pp_035/block_3_type_cognitive_hand', 'pp_035/block_4_type_limbic_hand']\n",
      "Processing pp 36...\n",
      "['pp_036/all_blocks', 'pp_036/block_0_type_localizer', 'pp_036/block_1_type_cognitive_eye', 'pp_036/block_2_type_limbic_eye', 'pp_036/block_3_type_limbic_hand', 'pp_036/block_4_type_cognitive_hand']\n",
      "Processing pp 37...\n",
      "['pp_037/all_blocks', 'pp_037/block_0_type_localizer', 'pp_037/block_1_type_limbic_hand', 'pp_037/block_2_type_cognitive_hand', 'pp_037/block_3_type_cognitive_eye', 'pp_037/block_4_type_limbic_eye']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pp 38...\n",
      "['pp_038/all_blocks', 'pp_038/block_0_type_localizer', 'pp_038/block_1_type_limbic_hand', 'pp_038/block_2_type_cognitive_hand', 'pp_038/block_3_type_limbic_eye', 'pp_038/block_4_type_cognitive_eye']\n",
      "Processing pp 39...\n",
      "['pp_039/all_blocks', 'pp_039/block_0_type_localizer', 'pp_039/block_1_type_limbic_hand', 'pp_039/block_2_type_cognitive_eye', 'pp_039/block_3_type_cognitive_hand', 'pp_039/block_4_type_limbic_eye']\n",
      "Processing pp 40...\n",
      "['pp_040/all_blocks', 'pp_040/block_0_type_localizer', 'pp_040/block_1_type_limbic_hand', 'pp_040/block_2_type_cognitive_eye', 'pp_040/block_3_type_limbic_eye', 'pp_040/block_4_type_cognitive_hand']\n",
      "Processing pp 41...\n",
      "['pp_041/all_blocks', 'pp_041/block_0_type_localizer', 'pp_041/block_1_type_limbic_hand', 'pp_041/block_2_type_limbic_eye', 'pp_041/block_3_type_cognitive_hand', 'pp_041/block_4_type_cognitive_eye']\n",
      "Processing pp 42...\n",
      "['pp_042/all_blocks', 'pp_042/block_0_type_localizer', 'pp_042/block_1_type_limbic_hand', 'pp_042/block_2_type_limbic_eye', 'pp_042/block_3_type_cognitive_eye', 'pp_042/block_4_type_cognitive_hand']\n",
      "Processing pp 43...\n",
      "['pp_043/all_blocks', 'pp_043/block_0_type_localizer', 'pp_043/block_1_type_limbic_eye', 'pp_043/block_2_type_cognitive_hand', 'pp_043/block_3_type_cognitive_eye', 'pp_043/block_4_type_limbic_hand']\n",
      "Processing pp 44...\n",
      "['pp_044/all_blocks', 'pp_044/block_0_type_localizer', 'pp_044/block_1_type_limbic_eye', 'pp_044/block_2_type_cognitive_hand', 'pp_044/block_3_type_limbic_hand', 'pp_044/block_4_type_cognitive_eye']\n",
      "Processing pp 45...\n",
      "['pp_045/all_blocks', 'pp_045/block_0_type_localizer', 'pp_045/block_1_type_limbic_eye', 'pp_045/block_2_type_cognitive_eye', 'pp_045/block_3_type_cognitive_hand', 'pp_045/block_4_type_limbic_hand']\n",
      "Processing pp 46...\n",
      "['pp_046/all_blocks', 'pp_046/block_0_type_localizer', 'pp_046/block_1_type_limbic_eye', 'pp_046/block_2_type_cognitive_eye', 'pp_046/block_3_type_limbic_hand', 'pp_046/block_4_type_cognitive_hand']\n",
      "Processing pp 47...\n",
      "['pp_047/all_blocks', 'pp_047/block_0_type_localizer', 'pp_047/block_1_type_limbic_eye', 'pp_047/block_2_type_limbic_hand', 'pp_047/block_3_type_cognitive_hand', 'pp_047/block_4_type_cognitive_eye']\n",
      "Processing pp 48...\n",
      "['pp_048/all_blocks', 'pp_048/block_0_type_localizer', 'pp_048/block_1_type_limbic_eye', 'pp_048/block_2_type_limbic_hand', 'pp_048/block_3_type_cognitive_eye', 'pp_048/block_4_type_cognitive_hand']\n",
      "Processing pp 49...\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for pp_num in range(0, 49):\n",
    "    print('Processing pp %d...' % (pp_num+1))\n",
    "    \n",
    "    pp_str = str(pp_num+1).zfill(3)\n",
    "    \n",
    "    pp_block_dirs = glob('pp_%s/*' % pp_str)\n",
    "    pp_block_dirs = [x for x in pp_block_dirs if not x.endswith('.feat')]\n",
    "    \n",
    "    for pp_block_dir in pp_block_dirs:\n",
    "        if 'all_blocks' in pp_block_dir or 'localizer' in pp_block_dir:\n",
    "            stim_onset_col = 'stimulus_onset_time'\n",
    "            cue_onset_col = 'cue_onset_time'\n",
    "        else:\n",
    "            stim_onset_col = 'stimulus_onset_time_block'\n",
    "            cue_onset_col = 'cue_onset_time_block'\n",
    "            \n",
    "        output_dir = os.path.join(pp_block_dir, 'evs')\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        design = pd.read_csv(os.path.join(pp_block_dir, 'trials.csv'))\n",
    "        design = design[['correct_answer','trial_type', 'block', 'phase_2', 'phase_4', 'cue', cue_onset_col, \n",
    "                         stim_onset_col, 'response_modality', 'null_trial']]\n",
    "        \n",
    "        # Get rid of all null trials\n",
    "        design = design.loc[design['null_trial'] != True]\n",
    "        \n",
    "        design['weight'] = 1\n",
    "        \n",
    "        # For the localizer block\n",
    "        if 0 in design['block'].unique():\n",
    "            subs = design.loc[design['block'] == 0]\n",
    "\n",
    "            for effector in subs['response_modality'].unique():\n",
    "                for cue in subs['cue'].unique():\n",
    "                    # response\n",
    "                    ev = subs.loc[(subs['response_modality'] == effector) & \n",
    "                                  (subs['cue'] == cue), [stim_onset_col, 'phase_4', 'weight']].values.tolist()\n",
    "                    \n",
    "                    with open(os.path.join(output_dir, 'ev_resp_%s_%s.txt' % (effector, cue)), 'wb') as f:\n",
    "                        for _list in ev:\n",
    "                            for _string in _list:\n",
    "                                f.write(str(_string) + '\\n')\n",
    "                            f.write('\\n')\n",
    "                    \n",
    "                    # responses\n",
    "                    ev = subs.loc[(subs['response_modality'] == effector) & \n",
    "                                  (subs['cue'] == cue), [cue_onset_col, 'phase_2', 'weight']].values.tolist()\n",
    "                    \n",
    "                    with open(os.path.join(output_dir, 'ev_cue_%s_%s.txt' % (effector, cue)), 'wb') as f:\n",
    "                        for _list in ev:\n",
    "                            for _string in _list:\n",
    "                                f.write(str(_string) + '\\n')\n",
    "                            f.write('\\n')\n",
    "                              \n",
    "            # The other stuff only for the other blocks\n",
    "            design = design.loc[design['block'] > 0]\n",
    "        \n",
    "        # For all cue types\n",
    "        for cue_type in design['cue'].unique():\n",
    "            # Get cue onset time, cue duration, and cue weight\n",
    "            ev = design.loc[(design['cue'] == cue_type), [cue_onset_col, 'phase_2', 'weight']].values.tolist()\n",
    "\n",
    "            with open(os.path.join(output_dir, 'ev_cue_%s.txt' % cue_type), 'wb') as f:\n",
    "                for _list in ev:\n",
    "                    for _string in _list:\n",
    "                        f.write(str(_string) + '\\n')\n",
    "                    f.write('\\n')\n",
    "\n",
    "        # For all stim types\n",
    "        for stim_type in design['correct_answer'].unique():\n",
    "            if np.isnan(stim_type):  # a nan stimtype corresponds to a null trial\n",
    "                continue\n",
    "\n",
    "            for cue_type in design['cue'].unique():\n",
    "                # Gets stimulus onset time, stimulus duration, and weight\n",
    "                ev = design.loc[(design['correct_answer'] == stim_type) &\n",
    "                                (design['cue'] == cue_type), \n",
    "                                [stim_onset_col, 'phase_4', 'weight']].values.tolist()\n",
    "\n",
    "                with open(os.path.join(output_dir, 'ev_stimulus_%d_%s.txt' % (stim_type, cue_type)), 'wb') as f:\n",
    "                    for _list in ev:\n",
    "                        for _string in _list:\n",
    "                            f.write(str(_string) + '\\n')\n",
    "                        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load FSL design text file for pp 1, and create for all other pps\n",
    "Before running this, the .fsf-design files for pp1 (each block) should be created manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for block_name in ['all_blocks', '_type_localizer', '_type_cognitive_hand', '_type_cognitive_eye', '_type_limbic_eye', '*_type_limbic_hand']:\n",
    "    # Get .fsf-file from pp001\n",
    "    pp_001_fn = glob(os.path.join('pp_001', '*' + block_name, 'design.fsf'))[0]\n",
    "    pp_001_block_name = pp_001_fn.split('/')[1]\n",
    "    \n",
    "    with open(pp_001_fn, 'rb') as f:\n",
    "        fsf_templ = f.readlines()\n",
    "\n",
    "    for pp in range(2, 49):\n",
    "        fsf_thispp = copy.copy(fsf_templ)\n",
    "        \n",
    "        # Get path to save the design.fsf file for this pp\n",
    "        this_pp_fn = os.path.join(glob(os.path.join('pp_' + str(pp).zfill(3), '*' + block_name))[0], 'design.fsf')\n",
    "        this_pp_block_name = this_pp_fn.split('/')[1]\n",
    "        \n",
    "        for i, line in enumerate(fsf_thispp):\n",
    "            if not block_name == 'all_blocks':\n",
    "                fsf_thispp[i] = re.sub(pp_001_block_name,\n",
    "                                       this_pp_block_name, line)\n",
    "            fsf_thispp[i] = re.sub('pp_001', 'pp_' + str(pp).zfill(3), fsf_thispp[i])\n",
    "\n",
    "        # Find fn for current pp\n",
    "        with open(this_pp_fn, 'wb') as f:\n",
    "            f.writelines(fsf_thispp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over subject and block directories, calling command line feat every time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "for sub in range(2, 3):\n",
    "    os.chdir(wd)\n",
    "    sub_dir = 'pp_' + str(sub).zfill(3)\n",
    "    block_dirs = [f for f in os.listdir(sub_dir) if os.path.isdir(os.path.join(sub_dir, f))]\n",
    "    block_dirs = [f for f in block_dirs if not '.feat' in f]\n",
    "    \n",
    "    for block_dir in block_dirs:\n",
    "        design_dir = os.path.join(wd, sub_dir, block_dir)\n",
    "        os.chdir(design_dir)\n",
    "        os.system('feat design.fsf')\n",
    "\n",
    "os.chdir(wd)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
